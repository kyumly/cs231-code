{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "해석\n",
    "- 당신은 이 과제에서 전체 신경망 기능을 제공하기 위해 많은 코드를 작성했습니다. Dropout, Batch Norm, conv2d는 컴퓨터비전에 핵심이다. 너는 또한 열심히 효과적으로 코드를 만들었고 벡터화 했다.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, PyTorch.\n",
    "\n",
    "해석\n",
    "- 하지만 이 과제의 마지막 부분에서는 아름다운 코드베이스를 남겨두고 대신 두 가지 인기 있는 딥 러닝 프레임워크 중 하나로 마이그레이션할 것입니다. 이 경우에는 PyTorch입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "## Why do we use deep learning frameworks?\n",
    "\n",
    "* Our code will now run on GPUs! This will allow our models to train much faster. When using a framework like PyTorch you can harness the power of the GPU for your own custom neural network architectures without having to write CUDA code directly (which is beyond the scope of this class).\n",
    "* In this class, we want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants! PyTorch is an excellent frameworks that will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* Finally, we want you to be exposed to the sort of deep learning code you might run into in academia or industry.\n",
    "\n",
    "해석\n",
    "- 우리의 코드는 이제 GPU에서 실행될 것입니다! 이렇게 하면 모델이 훨씬 빠르게 학습할 수 있습니다. PyTorch와 같은 프레임워크를 사용하면 CUDA 코드를 직접 작성하지 않고도(이 클래스의 범위를 벗어남) 사용자 지정 신경망 아키텍처에 GPU의 성능을 활용할 수 있습니다.\n",
    "- 이 수업에서는 프로젝트에 이러한 프레임워크 중 하나를 사용할 준비가 되어 사용하려는 모든 기능을 직접 작성하는 것보다 더 효율적으로 실험할 수 있기를 바랍니다.\n",
    "- 우리는 당신이 거인의 어깨 위에 서 있기를 바랍니다! PyTorch는 여러분의 삶을 훨씬 더 쉽게 만들어 줄 훌륭한 프레임워크이며, 이제 그들의 직감을 이해했으므로 자유롭게 사용할 수 있습니다 :)\n",
    "- 마지막으로, 우리는 여러분이 학계나 산업계에서 접할 수 있는 일종의 딥 러닝 코드에 노출되기를 바랍니다.\n",
    "\n",
    "## What is PyTorch?\n",
    "\n",
    "PyTorch is a system for executing dynamic computational graphs over Tensor objects that behave similarly as numpy ndarray. It comes with a powerful automatic differentiation engine that removes the need for manual back-propagation.\n",
    "\n",
    "해석\n",
    "- PyTorch는 numpy ndarray와 유사하게 동작하는 Tensor 개체에 대해 동적 계산 그래프를 실행하기 위한 시스템입니다.\n",
    "\n",
    "## How do I learn PyTorch?\n",
    "\n",
    "One of our former instructors, Justin Johnson, made an excellent [tutorial](https://github.com/jcjohnson/pytorch-examples) for PyTorch.\n",
    "- 해석\n",
    "\n",
    "You can also find the detailed [API doc](http://pytorch.org/docs/stable/index.html) here. If you have other questions that are not addressed by the API docs, the [PyTorch forum](https://discuss.pytorch.org/) is a much better place to ask than StackOverflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "This assignment has 5 parts. You will learn PyTorch on **three different levels of abstraction**, which will help you understand it better and prepare you for the final project. \n",
    "\n",
    "1. Part I, Preparation: we will use CIFAR-10 dataset.\n",
    "2. Part II, Barebones PyTorch: **Abstraction level 1**, we will work directly with the lowest-level PyTorch Tensors. \n",
    "3. Part III, PyTorch Module API: **Abstraction level 2**, we will use `nn.Module` to define arbitrary neural network architecture. \n",
    "4. Part IV, PyTorch Sequential API: **Abstraction level 3**, we will use `nn.Sequential` to define a linear feed-forward network very conveniently. \n",
    "5. Part V, CIFAR-10 open-ended challenge: please implement your own network to get as high accuracy as possible on CIFAR-10. You can experiment with any layer, optimizer, hyperparameters or other advanced features. \n",
    "\n",
    "\n",
    "해석\n",
    "- 1. 파트 I, 준비: CIFAR-10 데이터 세트를 사용합니다.\n",
    "- 2. 파트 II, Barebones PyTorch: **추상화 수준 1**, 가장 낮은 수준의 PyTorch Tensor로 직접 작업합니다.\n",
    "- 3. 파트 III, PyTorch 모듈 API: **추상화 수준 2**, `nn.Module`을 사용하여 임의의 신경망 아키텍처를 정의합니다.\n",
    "- 4. 파트 IV, PyTorch Sequential API: **추상화 수준 3**, `nn.Sequential`을 사용하여 매우 편리하게 선형 피드포워드 네트워크를 정의합니다.\n",
    "- 5. 파트 V, CIFAR-10 개방형 도전: CIFAR-10에서 가능한 한 높은 정확도를 얻기 위해 자체 네트워크를 구현하십시오. 모든 레이어, 옵티마이저, 하이퍼파라미터 또는 기타 고급 기능을 실험할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "Here is a table of comparison:\n",
    "\n",
    "| API           | Flexibility | Convenience |\n",
    "|---------------|-------------|-------------|\n",
    "| Barebone      | High        | Low         |\n",
    "| `nn.Module`     | High        | Medium      |\n",
    "| `nn.Sequential` | Low         | High        |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# GPU\n",
    "\n",
    "You can manually switch to a GPU device on Colab by clicking `Runtime -> Change runtime type` and selecting `GPU` under `Hardware Accelerator`. You should do this before running the following cells to import packages, since the kernel gets restarted upon switching runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Preparation\n",
    "\n",
    "Now, let's load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that.\n",
    "\n",
    "In previous parts of the assignment we had to write our own code to download the CIFAR-10 dataset, preprocess it, and iterate through it in minibatches; PyTorch provides convenient tools to automate this process for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Barebones PyTorch\n",
    "\n",
    "PyTorch ships with high-level APIs to help us define model architectures conveniently, which we will cover in Part II of this tutorial. In this section, we will start with the barebone PyTorch elements to understand the autograd engine better. After this exercise, you will come to appreciate the high-level model API more.\n",
    "\n",
    "해석\n",
    "- PyTorch는 모델 아키텍처를 편리하게 정의하는 데 도움이 되는 높은 수준의 API와 함께 제공되며 이 자습서의 2부에서 다룰 것입니다. 이 섹션에서는 autograd 엔진을 더 잘 이해하기 위해 베어본 PyTorch 요소부터 시작하겠습니다. 이 실습을 마치면 고급 모델 API를 더 높이 평가하게 될 것입니다.\n",
    "\n",
    "We will start with a simple fully-connected ReLU network with two hidden layers and no biases for CIFAR classification. \n",
    "This implementation computes the forward pass using operations on PyTorch Tensors, and uses PyTorch autograd to compute gradients. It is important that you understand every line, because you will write a harder version after the example.\n",
    "\n",
    "해석\n",
    "- CIFAR 분류를 위한 편향이 없고 두 개의 은닉층이 있는 완전히 연결된 간단한 ReLU 네트워크로 시작하겠습니다. 이 구현은 PyTorch Tensor에서 작업을 사용하여 순방향 패스를 계산하고 PyTorch autograd를 사용하여 그래디언트를 계산합니다. 예제 다음에 더 어려운 버전을 작성할 것이기 때문에 모든 줄을 이해하는 것이 중요합니다.\n",
    "\n",
    "\n",
    "When we create a PyTorch Tensor with `requires_grad=True`, then operations involving that Tensor will not just compute values; they will also build up a computational graph in the background, allowing us to easily backpropagate through the graph to compute gradients of some Tensors with respect to a downstream loss. Concretely if x is a Tensor with `x.requires_grad == True` then after backpropagation `x.grad` will be another Tensor holding the gradient of x with respect to the scalar loss at the end.\n",
    "해석\n",
    "- `requires_grad=True`로 PyTorch Tensor를 만들 때 해당 Tensor와 관련된 작업은 단순히 값을 계산하는 것이 아닙니다. 또한 백그라운드에서 계산 그래프를 구축하여 그래프를 통해 쉽게 역전파하여 다운스트림 손실과 관련하여 일부 Tensor의 그래디언트를 계산할 수 있습니다. 구체적으로 x가 `x.requires_grad == True`인 Tensor이면 역전파 후 `x.grad`는 마지막에 스칼라 손실에 대해 x의 기울기를 유지하는 또 다른 Tensor가 됩니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### PyTorch Tensors: Flatten Function\n",
    "A PyTorch Tensor is conceptionally similar to a numpy array: it is an n-dimensional grid of numbers, and like numpy PyTorch provides many functions to efficiently operate on Tensors. As a simple example, we provide a `flatten` function below which reshapes image data for use in a fully-connected neural network.\n",
    "\n",
    "\n",
    "해석\n",
    "- PyTorch Tensor는 개념적으로 numpy 배열과 유사합니다. n차원 숫자 그리드이며 numpy PyTorch와 마찬가지로 Tensor에서 효율적으로 작동하는 많은 기능을 제공합니다. 간단한 예로, 완전히 연결된 신경망에서 사용하기 위해 이미지 데이터를 재구성하는 'flatten' 함수를 제공합니다.\n",
    "\n",
    "\n",
    "Recall that image data is typically stored in a Tensor of shape N x C x H x W, where:\n",
    "\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "해석\n",
    "- 이미지 데이터는 일반적으로 N x C x H x W 모양의 Tensor에 저장된다는 점을 상기하십시오.\n",
    "- N은 데이터 포인트의 수입니다.\n",
    "- C는 채널 수\n",
    "- H는 중간 특징 맵의 높이(픽셀 단위)입니다.\n",
    "- W는 중간 특징 맵의 높이(픽셀 단위)입니다.\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we use fully connected affine layers to process the image, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"flatten\" operation to collapse the `C x H x W` values per representation into a single long vector. The flatten function below first reads in the N, C, H, and W values from a given batch of data, and then returns a \"view\" of that data. \"View\" is analogous to numpy's \"reshape\" method: it reshapes x's dimensions to be N x ??, where ?? is allowed to be anything (in this case, it will be C x H x W, but we don't need to specify that explicitly).\n",
    "\n",
    "해석\n",
    "- 이것은 중간 피처가 서로 상대적인 위치에 대한 공간적 이해가 필요한 2D 컨볼루션과 같은 것을 수행할 때 데이터를 나타내는 올바른 방법입니다. 그러나 완전히 연결된 아핀 레이어를 사용하여 이미지를 처리할 때 각 데이터 포인트가 단일 벡터로 표현되기를 원합니다. 데이터의 다른 채널, 행 및 열을 분리하는 것은 더 이상 유용하지 않습니다. 따라서 \"평평화\" 작업을 사용하여 표현당 `C x H x W` 값을 하나의 긴 벡터로 축소합니다. 아래의 flatten 함수는 먼저 주어진 데이터 배치에서 N, C, H 및 W 값을 읽은 다음 해당 데이터의 \"보기\"를 반환합니다. \"View\"는 numpy의 \"reshape\" 방법과 유사합니다. x의 차원을 N x ??로 변경합니다. 여기서 ?? 무엇이든 될 수 있습니다(이 경우 C x H x W이지만 명시적으로 지정할 필요는 없습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "### Barebones PyTorch: Two-Layer Network\n",
    "\n",
    "Here we define a function `two_layer_fc` which performs the forward pass of a two-layer fully-connected ReLU network on a batch of image data. After defining the forward pass we check that it doesn't crash and that it produces outputs of the right shape by running zeros through the network.\n",
    "\n",
    "You don't have to write any code here, but it's important that you read and understand the implementation.\n",
    "\n",
    "해석\n",
    "- 여기에서 우리는 이미지 데이터 배치에서 완전히 연결된 2계층 ReLU 네트워크의 순방향 전달을 수행하는 `two_layer_fc` 함수를 정의합니다. 순방향 패스를 정의한 후 우리는 그것이 충돌하지 않고 네트워크를 통해 0을 실행하여 올바른 모양의 출력을 생성하는지 확인합니다.\n",
    "- 여기에 코드를 작성할 필요는 없지만 구현을 읽고 이해하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "def two_layer_fc(x, params):\n",
    "    \"\"\"\n",
    "    A fully-connected neural networks; the architecture is:\n",
    "    NN is fully connected -> ReLU -> fully connected layer.\n",
    "    Note that this function only defines the forward pass; \n",
    "    PyTorch will take care of the backward pass for us.\n",
    "\n",
    "    파트.1 완전 신경망 아키텍처\n",
    "    NN는 fully connected -> Relu -> Fully connected 레이어이다.\n",
    "    이 함수는 오적 Forward pass 만한다\n",
    "    파이토치는 Backward를 처리할것이다.\n",
    "\n",
    "    The input to the network will be a minibatch of data, of shape\n",
    "    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n",
    "    and the output layer will produce scores for C classes.\n",
    "\n",
    "    파트2.input 데이터\n",
    "    네트워크에 대한 입력은 형태의 데이터 미니배치가 될 것입니다.\n",
    "     (N, d1, ..., dM) 여기서 d1 * ... * dM = D. 은닉층은 H 단위를 가지며,\n",
    "     출력 레이어는 C 클래스에 대한 점수를 생성합니다.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n",
    "      input data.\n",
    "    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n",
    "      w1 has shape (D, H) and w2 has shape (H, C).\n",
    "\n",
    "    x: 미니배치를 제공하는 (N, d1, ..., dM) 모양의 PyTorch Tensor\n",
    "       입력 데이터.\n",
    "     params: 네트워크에 가중치를 부여하는 PyTorch Tensor 목록 [w1, w2]\n",
    "       w1의 모양은 (D, H)이고 w2의 모양은 (H, C)입니다.\n",
    "\n",
    "    Returns:\n",
    "    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n",
    "      the input data x.\n",
    "\n",
    "    점수: 다음에 대한 분류 점수를 제공하는 형태(N, C)의 PyTorch Tensor 입력 데이터 x.\n",
    "\n",
    "    \"\"\"\n",
    "    # first we flatten the image\n",
    "    x = flatten(x)  # shape: [batch_size, C x H x W]\n",
    "    \n",
    "    w1, w2 = params\n",
    "    \n",
    "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "    # PyTorch to build a computational graph, allowing automatic computation of\n",
    "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "    # don't need to keep references to intermediate values.\n",
    "    # you can also use `.clamp(min=0)`, equivalent to F.relu()\n",
    "    x = F.relu(x.mm(w1))\n",
    "    x = x.mm(w2)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def two_layer_fc_test():\n",
    "    hidden_layer_size = 42\n",
    "    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
    "    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n",
    "    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n",
    "    scores = two_layer_fc(x, [w1, w2])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: Three-Layer ConvNet\n",
    "\n",
    "Here you will complete the implementation of the function `three_layer_convnet`, which will perform the forward pass of a three-layer convolutional network. Like above, we can immediately test our implementation by passing zeros through the network. The network should have the following architecture:\n",
    "\n",
    "1. A convolutional layer (with bias) with `channel_1` filters, each with shape `KW1 x KH1`, and zero-padding of two\n",
    "2. ReLU nonlinearity\n",
    "3. A convolutional layer (with bias) with `channel_2` filters, each with shape `KW2 x KH2`, and zero-padding of one\n",
    "4. ReLU nonlinearity\n",
    "5. Fully-connected layer with bias, producing scores for C classes.\n",
    "\n",
    "Note that we have **no softmax activation** here after our fully-connected layer: this is because PyTorch's cross entropy loss performs a softmax activation for you, and by bundling that step in makes computation more efficient.\n",
    "\n",
    "**HINT**: For convolutions: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; pay attention to the shapes of convolutional filters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    Performs the forward pass of a three-layer convolutional network with the\n",
    "    architecture defined above.\n",
    "\n",
    "    Inputs:\n",
    "    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n",
    "    - params: A list of PyTorch Tensors giving the weights and biases for the\n",
    "      network; should contain the following:\n",
    "      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n",
    "        for the first convolutional layer\n",
    "      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n",
    "        convolutional layer\n",
    "      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n",
    "        weights for the second convolutional layer\n",
    "      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n",
    "        convolutional layer\n",
    "      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n",
    "        figure out what the shape should be?\n",
    "      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n",
    "        figure out what the shape should be?\n",
    "    \n",
    "    Returns:\n",
    "    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    ################################################################################\n",
    "    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # conv_layer1 = nn.Conv2d(\n",
    "    #     in_channels=10,\n",
    "    #     out_channels=20,\n",
    "    #     kernel_size=\n",
    "    #)\n",
    "    # p = int((conv_w1.size()[2] - 1) /2)\n",
    "    # print(p)\n",
    "    # conv1_layer = nn.Conv2d(\n",
    "    #     in_channels=conv_w1.size()[1],\n",
    "    #     out_channels=conv_w1.size()[0],\n",
    "    #     padding=(p,p),\n",
    "    #     kernel_size=(conv_w1.size()[2], conv_w1.size()[3],)\n",
    "    # )(x)\n",
    "    #\n",
    "    # print(\"conv1_layer size : \", conv1_layer.size())\n",
    "    # v1 = F.relu(conv1_layer)\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # p = int((conv_w2.size()[2] - 1) /2)\n",
    "    # conv2_layer = nn.Conv2d(\n",
    "    #     in_channels=conv_w2.size()[1],\n",
    "    #     out_channels=conv_w2.size()[0],\n",
    "    #     padding=(p,p),\n",
    "    #     kernel_size=(conv_w2.size()[2], conv_w2.size()[3])\n",
    "    # )(v1)\n",
    "    #\n",
    "    # print(\"conv2_layer size : \", conv2_layer.size())\n",
    "    # v2 = F.relu(conv2_layer)\n",
    "    #\n",
    "    #\n",
    "    # v3 = flatten(v2)\n",
    "    # scores = nn.Linear(fc_w.size()[0], fc_b.size()[0])(v3)\n",
    "    #\n",
    "    # print(\"최종 : \", scores.size())\n",
    "\n",
    "\n",
    "    p = int((conv_w1.size()[2] - 1) /2)\n",
    "\n",
    "    h1 = torch.nn.functional.conv2d(x, conv_w1, conv_b1, padding=p)\n",
    "    h1 = torch.nn.functional.relu(h1)\n",
    "\n",
    "    p = int((conv_w2.size()[2] - 1) /2)\n",
    "    h2 = torch.nn.functional.conv2d(h1, conv_w2, conv_b2, padding=p)\n",
    "    h2 = torch.nn.functional.relu(h2)\n",
    "    h2 = flatten(h2)\n",
    "    scores = h2.mm(fc_w) + fc_b\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the forward pass of the ConvNet above, run the following cell to test your implementation.\n",
    "\n",
    "When you run this function, scores should have shape (64, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ],
    "test": "barebones_output_shape"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "\n",
    "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b1 = torch.zeros((6,))  # out_channel\n",
    "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
    "    conv_b2 = torch.zeros((9,))  # out_channel\n",
    "\n",
    "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
    "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
    "    fc_b = torch.zeros(10)\n",
    "\n",
    "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "three_layer_convnet_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: Initialization\n",
    "Let's write a couple utility methods to initialize the weight matrices for our models.\n",
    "\n",
    "- `random_weight(shape)` initializes a weight tensor with the Kaiming normalization method.\n",
    "- `zero_weight(shape)` initializes a weight tensor with all zeros. Useful for instantiating bias parameters.\n",
    "\n",
    "해석\n",
    "- `random_weight(shape)`는 Kaiming 정규화 방법으로 가중치 텐서를 초기화합니다.\n",
    "- `zero_weight(shape)`는 모두 0으로 가중치 텐서를 초기화합니다. 편향 매개변수를 인스턴스화하는 데 유용합니다.\n",
    "\n",
    "The `random_weight` function uses the Kaiming normal initialization method, described in:\n",
    "\n",
    "해석\n",
    "- 'random_weight' 함수는 다음에서 설명하는 Kaiming 일반 초기화 방법을 사용합니다.\n",
    "\n",
    "He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852\n",
    "- He et al, *정류기에 대해 자세히 알아보기: ImageNet 분류에서 인간 수준의 성능 능가*, ICCV 2015, https://arxiv.org/abs/1502.01852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7188,  0.6404,  0.6799,  0.6628,  2.0171],\n        [-0.4081, -0.7630, -0.7367, -2.0075,  0.2136],\n        [-0.3123,  0.0113, -1.2936, -0.7772, -0.7979]], requires_grad=True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_weight(shape):\n",
    "    \"\"\"\n",
    "    Create random Tensors for weights; setting requires_grad=True means that we\n",
    "    want to compute gradients for these Tensors during the backward pass.\n",
    "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
    "\n",
    "    가중치에 대한 임의의 텐서를 생성합니다. 설정 required_grad=True는 우리가\n",
    "    백워드 패스 동안 이러한 텐서에 대한 그래디언트를 계산하려고 합니다.\n",
    "    우리는 Kaiming 정규화를 사용합니다: sqrt(2 / fan_in)\n",
    "    \"\"\"\n",
    "    if len(shape) == 2:  # FC weight\n",
    "        fan_in = shape[0]\n",
    "    else:\n",
    "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
    "    # randn is standard normal distribution generator. \n",
    "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "    w.requires_grad = True\n",
    "    return w\n",
    "\n",
    "def zero_weight(shape):\n",
    "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "# create a weight of shape [3 x 5]\n",
    "# you should see the type `torch.cuda.FloatTensor` if you use GPU. \n",
    "# Otherwise it should be `torch.FloatTensor`\n",
    "random_weight((3, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barebones PyTorch: Check Accuracy\n",
    "When training the model we will use the following function to check the accuracy of our model on the training or validation sets.\n",
    "\n",
    "When checking accuracy we don't need to compute any gradients; as a result we don't need PyTorch to build a computational graph for us when we compute scores. To prevent a graph from being built we scope our computation under a `torch.no_grad()` context manager.\n",
    "\n",
    "해석\n",
    "- 모델을 교육할 때 다음 기능을 사용하여 교육 또는 검증 세트에서 모델의 정확도를 확인합니다.\n",
    "- 정확도를 확인할 때 그라디언트를 계산할 필요가 없습니다. 결과적으로 점수를 계산할 때 계산 그래프를 작성하기 위해 PyTorch가 필요하지 않습니다. 그래프가 작성되는 것을 방지하기 위해 `torch.no_grad()` 컨텍스트 관리자에서 계산 범위를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part2(loader, model_fn, params):\n",
    "    \"\"\"\n",
    "    Check the accuracy of a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - loader: A DataLoader for the data split we want to check\n",
    "    - model_fn: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model_fn(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "    \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    split = 'val' if loader.dataset.train else 'test'\n",
    "    print('Checking accuracy on the %s set' % split)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.int64)\n",
    "            scores = model_fn(x, params)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: Training Loop\n",
    "We can now set up a basic training loop to train our network. We will train the model using stochastic gradient descent without momentum. We will use `torch.functional.cross_entropy` to compute the loss; you can [read about it here](http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
    "\n",
    "The training loop takes as input the neural network function, a list of initialized parameters (`[w1, w2]` in our example), and learning rate.\n",
    "\n",
    "해석\n",
    "- 이제 기본 훈련 루프를 설정하여 네트워크를 훈련할 수 있습니다. 모멘텀 없이 확률적 경사하강법을 사용하여 모델을 훈련할 것입니다. 손실을 계산하기 위해 `torch.functional.cross_entropy`를 사용할 것입니다. [여기에서 읽을 수 있습니다](http://pytorch.org/docs/stable/nn.html#cross-entropy).\n",
    "\n",
    "- 훈련 루프는 신경망 함수, 초기화된 매개변수 목록(이 예에서는 `[w1, w2]`) 및 학습률을 입력으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "def train_part2(model_fn, params, learning_rate):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: A Python function that performs the forward pass of the model.\n",
    "      It should have the signature scores = model_fn(x, params) where x is a\n",
    "      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n",
    "      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n",
    "      scores for the elements in x.\n",
    "    - params: List of PyTorch Tensors giving weights for the model\n",
    "    - learning_rate: Python scalar giving the learning rate to use for SGD\n",
    "    \n",
    "    Returns: Nothing\n",
    "    \"\"\"\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        # Move the data to the proper device (GPU or CPU)\n",
    "        x = x.to(device=device, dtype=dtype)\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass: compute scores and loss\n",
    "        scores = model_fn(x, params)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        # Backward pass: PyTorch figures out which Tensors in the computational\n",
    "        # graph has requires_grad=True and uses backpropagation to compute the\n",
    "        # gradient of the loss with respect to these Tensors, and stores the\n",
    "        # gradients in the .grad attribute of each Tensor.\n",
    "\n",
    "        # 역방향 패스: PyTorch는 연산에서 어떤 Tensor를 파악합니다.\n",
    "        # 그래프는 require_grad=True이고 역전파를 사용하여\n",
    "        # 이러한 Tensor에 대한 손실의 기울기, 그리고 저장\n",
    "        # 각 Tensor의 .grad 속성의 기울기.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters. We don't want to backpropagate through the\n",
    "        # parameter updates, so we scope the updates under a torch.no_grad()\n",
    "        # context manager to prevent a computational graph from being built.\n",
    "\n",
    "        # 매개변수를 업데이트합니다. 우리는 역전파를 원하지 않습니다.\n",
    "        # 매개변수 업데이트, 그래서 우리는 torch.no_grad()에서 업데이트 범위를 지정합니다.\n",
    "        # 계산 그래프가 작성되는 것을 방지하는 컨텍스트 관리자.\n",
    "        with torch.no_grad():\n",
    "            for w in params:\n",
    "                w -= learning_rate * w.grad\n",
    "\n",
    "                # Manually zero the gradients after running the backward pass\n",
    "                w.grad.zero_()\n",
    "\n",
    "        if t % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            check_accuracy_part2(loader_val, model_fn, params)\n",
    "            print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: Train a Two-Layer Network\n",
    "Now we are ready to run the training loop. We need to explicitly allocate tensors for the fully connected weights, `w1` and `w2`. \n",
    "\n",
    "Each minibatch of CIFAR has 64 examples, so the tensor shape is `[64, 3, 32, 32]`. \n",
    "\n",
    "After flattening, `x` shape should be `[64, 3 * 32 * 32]`. This will be the size of the first dimension of `w1`. \n",
    "The second dimension of `w1` is the hidden layer size, which will also be the first dimension of `w2`. \n",
    "\n",
    "Finally, the output of the network is a 10-dimensional vector that represents the probability distribution over 10 classes. \n",
    "\n",
    "You don't need to tune any hyperparameters but you should see accuracies above 40% after training for one epoch.\n",
    "\n",
    "해석\n",
    "- 이제 훈련 루프를 실행할 준비가 되었습니다. 완전히 연결된 가중치인 'w1' 및 'w2'에 대한 텐서를 명시적으로 할당해야 합니다.\n",
    "\n",
    "- CIFAR의 각 미니 배치에는 64개의 예제가 있으므로 텐서 모양은 '[64, 3, 32, 32]'입니다.\n",
    "\n",
    "- 평면화 후 `x` 모양은 `[64, 3 * 32 * 32]`이어야 합니다. 이것은 'w1'의 첫 번째 차원의 크기가 됩니다. 'w1'의 두 번째 차원은 숨겨진 레이어 크기이며 'w2'의 첫 번째 차원이기도 합니다.\n",
    "\n",
    "- 마지막으로 네트워크의 출력은 10개 클래스에 대한 확률 분포를 나타내는 10차원 벡터입니다.\n",
    "\n",
    "- 하이퍼파라미터를 조정할 필요는 없지만 한 에포크 동안 훈련한 후 정확도가 40% 이상이어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.8649\n",
      "Checking accuracy on the val set\n",
      "Got 156 / 1000 correct (15.60%)\n",
      "\n",
      "Iteration 100, loss = 2.2534\n",
      "Checking accuracy on the val set\n",
      "Got 269 / 1000 correct (26.90%)\n",
      "\n",
      "Iteration 200, loss = 2.5414\n",
      "Checking accuracy on the val set\n",
      "Got 361 / 1000 correct (36.10%)\n",
      "\n",
      "Iteration 300, loss = 2.3284\n",
      "Checking accuracy on the val set\n",
      "Got 412 / 1000 correct (41.20%)\n",
      "\n",
      "Iteration 400, loss = 2.0460\n",
      "Checking accuracy on the val set\n",
      "Got 402 / 1000 correct (40.20%)\n",
      "\n",
      "Iteration 500, loss = 1.8099\n",
      "Checking accuracy on the val set\n",
      "Got 431 / 1000 correct (43.10%)\n",
      "\n",
      "Iteration 600, loss = 1.7927\n",
      "Checking accuracy on the val set\n",
      "Got 410 / 1000 correct (41.00%)\n",
      "\n",
      "Iteration 700, loss = 1.5818\n",
      "Checking accuracy on the val set\n",
      "Got 410 / 1000 correct (41.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
    "w2 = random_weight((hidden_layer_size, 10))\n",
    "\n",
    "train_part2(two_layer_fc, [w1, w2], learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BareBones PyTorch: Training a ConvNet\n",
    "\n",
    "In the below you should use the functions defined above to train a three-layer convolutional network on CIFAR. The network should have the following architecture:\n",
    "\n",
    "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer (with bias) to compute scores for 10 classes\n",
    "\n",
    "You should initialize your weight matrices using the `random_weight` function defined above, and you should initialize your bias vectors using the `zero_weight` function above.\n",
    "\n",
    "You don't need to tune any hyperparameters, but if everything works correctly you should achieve an accuracy above 42% after one epoch.\n",
    "\n",
    "해석\n",
    "- 아래에서는 위에서 정의한 함수를 사용하여 CIFAR에서 3계층 컨볼루션 네트워크를 훈련해야 합니다. 네트워크에는 다음 아키텍처가 있어야 합니다.\n",
    "\n",
    "- 1. 제로 패딩이 2인 32개의 5x5 필터가 있는 컨벌루션 레이어(바이어스 포함)\n",
    "- 2. 렐루\n",
    "- 3. 제로 패딩이 1인 16개의 3x3 필터가 있는 컨벌루션 레이어(바이어스 포함)\n",
    "- 4. 렐루\n",
    "- 5. 10개의 클래스에 대한 점수를 계산하기 위한 완전 연결 레이어(바이어스 있음)\n",
    "\n",
    "- 위에서 정의한 'random_weight' 함수를 사용하여 가중치 행렬을 초기화해야 하며 위의 'zero_weight' 함수를 사용하여 편향 벡터를 초기화해야 합니다.\n",
    "\n",
    "- 하이퍼파라미터를 조정할 필요는 없지만 모든 것이 올바르게 작동한다면 한 에포크 후에 42% 이상의 정확도를 달성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "test": "barebones_accuracy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384, 10])\n",
      "Iteration 0, loss = 2.8227\n",
      "Checking accuracy on the val set\n",
      "Got 87 / 1000 correct (8.70%)\n",
      "\n",
      "Iteration 100, loss = 1.8751\n",
      "Checking accuracy on the val set\n",
      "Got 362 / 1000 correct (36.20%)\n",
      "\n",
      "Iteration 200, loss = 1.7454\n",
      "Checking accuracy on the val set\n",
      "Got 381 / 1000 correct (38.10%)\n",
      "\n",
      "Iteration 300, loss = 1.5471\n",
      "Checking accuracy on the val set\n",
      "Got 430 / 1000 correct (43.00%)\n",
      "\n",
      "Iteration 400, loss = 1.9071\n",
      "Checking accuracy on the val set\n",
      "Got 439 / 1000 correct (43.90%)\n",
      "\n",
      "Iteration 500, loss = 1.6072\n",
      "Checking accuracy on the val set\n",
      "Got 448 / 1000 correct (44.80%)\n",
      "\n",
      "Iteration 600, loss = 1.6211\n",
      "Checking accuracy on the val set\n",
      "Got 455 / 1000 correct (45.50%)\n",
      "\n",
      "Iteration 700, loss = 1.7955\n",
      "Checking accuracy on the val set\n",
      "Got 456 / 1000 correct (45.60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "conv_w1 = None\n",
    "conv_b1 = None\n",
    "conv_w2 = None\n",
    "conv_b2 = None\n",
    "fc_w = None\n",
    "fc_b = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\n",
    "conv_w1 = random_weight((32, 3, 5, 5))\n",
    "\n",
    "conv_b1 = zero_weight(channel_1)\n",
    "\n",
    "conv_w2 = random_weight((16, 32, 3, 3))\n",
    "conv_b2 = zero_weight(channel_2)\n",
    "\n",
    "fc_w = random_weight(((16 * 32 * 32), 10))\n",
    "print(fc_w.size())\n",
    "fc_b = random_weight([10])\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "train_part2(three_layer_convnet, params, learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. PyTorch Module API\n",
    "\n",
    "Barebone PyTorch requires that we track all the parameter tensors by hand. This is fine for small networks with a few tensors, but it would be extremely inconvenient and error-prone to track tens or hundreds of tensors in larger networks.\n",
    "\n",
    "PyTorch provides the `nn.Module` API for you to define arbitrary network architectures, while tracking every learnable parameters for you. In Part II, we implemented SGD ourselves. PyTorch also provides the `torch.optim` package that implements all the common optimizers, such as RMSProp, Adagrad, and Adam. It even supports approximate second-order methods like L-BFGS! You can refer to the [doc](http://pytorch.org/docs/master/optim.html) for the exact specifications of each optimizer.\n",
    "\n",
    "해석\n",
    "- Barebone PyTorch에서는 모든 매개변수 텐서를 직접 추적해야 합니다. 이는 소수의 텐서가 있는 소규모 네트워크에는 적합하지만 대규모 네트워크에서 수십 또는 수백 개의 텐서를 추적하는 것은 매우 불편하고 오류가 발생하기 쉽습니다.\n",
    "- PyTorch는 학습 가능한 모든 매개변수를 추적하면서 임의의 네트워크 아키텍처를 정의할 수 있는 `nn.Module` API를 제공합니다. 2부에서는 SGD를 직접 구현했습니다. PyTorch는 또한 RMSProp, Adagrad 및 Adam과 같은 모든 공통 옵티마이저를 구현하는 `torch.optim` 패키지를 제공합니다. L-BFGS와 같은 대략적인 2차 방법도 지원합니다! 각 옵티마이저의 정확한 사양은 [문서](http://pytorch.org/docs/master/optim.html)를 참조하세요.\n",
    "\n",
    "\n",
    "To use the Module API, follow the steps below:\n",
    "\n",
    "1. Subclass `nn.Module`. Give your network class an intuitive name like `TwoLayerFC`. \n",
    "\n",
    "2. In the constructor `__init__()`, define all the layers you need as class attributes. Layer objects like `nn.Linear` and `nn.Conv2d` are themselves `nn.Module` subclasses and contain learnable parameters, so that you don't have to instantiate the raw tensors yourself. `nn.Module` will track these internal parameters for you. Refer to the [doc](http://pytorch.org/docs/master/nn.html) to learn more about the dozens of builtin layers. **Warning**: don't forget to call the `super().__init__()` first!\n",
    "\n",
    "3. In the `forward()` method, define the *connectivity* of your network. You should use the attributes defined in `__init__` as function calls that take tensor as input and output the \"transformed\" tensor. Do *not* create any new layers with learnable parameters in `forward()`! All of them must be declared upfront in `__init__`. \n",
    "\n",
    "After you define your Module subclass, you can instantiate it as an object and call it just like the NN forward function in part II.\n",
    "\n",
    "\n",
    "해석\n",
    "- 1. 서브클래스 `nn.Module`. 네트워크 클래스에 `TwoLayerFC`와 같은 직관적인 이름을 지정하십시오.\n",
    "\n",
    "- 2. 생성자 `__init__()`에서 필요한 모든 레이어를 클래스 속성으로 정의합니다. `nn.Linear` 및 `nn.Conv2d`와 같은 계층 객체는 그 자체로 `nn.Module` 하위 클래스이며 학습 가능한 매개변수를 포함하므로 원시 텐서를 직접 인스턴스화할 필요가 없습니다. `nn.Module`은 이러한 내부 매개변수를 추적합니다. 수십 개의 내장 레이어에 대한 자세한 내용은 [문서](http://pytorch.org/docs/master/nn.html)를 참조하세요. **경고**: `super().__init__()`를 먼저 호출하는 것을 잊지 마세요!\n",
    "\n",
    "- 3. `forward()` 메서드에서 네트워크의 *연결성*을 정의합니다. 텐서를 입력으로 사용하고 \"변환된\" 텐서를 출력하는 함수 호출로 `__init__`에 정의된 속성을 사용해야 합니다. `forward()`에서 학습 가능한 매개변수로 새 레이어를 만들지 *마세요*! 모두 `__init__`에서 미리 선언해야 합니다.\n",
    "\n",
    "Module 하위 클래스를 정의한 후 이를 개체로 인스턴스화하고 II부의 NN 전달 함수처럼 호출할 수 있습니다.\n",
    "\n",
    "### Module API: Two-Layer Network\n",
    "Here is a concrete example of a 2-layer fully connected network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        # assign layer objects to class attributes\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # nn.init package contains convenient initialization methods\n",
    "        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        x = flatten(x)\n",
    "        scores = self.fc2(F.relu(self.fc1(x)))\n",
    "        return scores\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    input_size = 50\n",
    "    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
    "    model = TwoLayerFC(input_size, 42, 10)\n",
    "    scores = model(x)\n",
    "    print(scores.size())  # you should see [64, 10]\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Three-Layer ConvNet\n",
    "It's your turn to implement a 3-layer ConvNet followed by a fully connected layer. The network architecture should be the same as in Part II:\n",
    "\n",
    "1. Convolutional layer with `channel_1` 5x5 filters with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer with `channel_2` 3x3 filters with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer to `num_classes` classes\n",
    "\n",
    "You should initialize the weight matrices of the model using the Kaiming normal initialization method.\n",
    "\n",
    "**HINT**: http://pytorch.org/docs/stable/nn.html#conv2d\n",
    "\n",
    "After you implement the three-layer ConvNet, the `test_ThreeLayerConvNet` function will run your implementation; it should print `(64, 10)` for the shape of the output scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "test": "module_output_shape"
   },
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=channel_1, kernel_size=(5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel_1, out_channels=channel_2, kernel_size=(3,3), padding=1)\n",
    "        self.fc = nn.Linear(16384, num_classes)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        v1 = F.relu(self.conv1(x))\n",
    "        v2 = F.relu(self.conv2(v1))\n",
    "        v3 = flatten(v2)\n",
    "        scores = self.fc(v3)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return scores\n",
    "\n",
    "\n",
    "# def test_ThreeLayerConvNet():\n",
    "#     x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
    "#     model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
    "#     scores = model(x)\n",
    "#     print(scores.size())  # you should see [64, 10]\n",
    "# test_ThreeLayerConvNet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Check Accuracy\n",
    "Given the validation or test set, we can check the classification accuracy of a neural network. \n",
    "\n",
    "This version is slightly different from the one in part II. You don't manually pass in the parameters anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Training Loop\n",
    "We also use a slightly different training loop. Rather than updating the values of the weights ourselves, we use an Optimizer object from the `torch.optim` package, which abstract the notion of an optimization algorithm and provides implementations of most of the algorithms commonly used to optimize neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Train a Two-Layer Network\n",
    "Now we are ready to run the training loop. In contrast to part II, we don't explicitly allocate parameter tensors anymore.\n",
    "\n",
    "Simply pass the input size, hidden layer size, and number of classes (i.e. output size) to the constructor of `TwoLayerFC`. \n",
    "\n",
    "You also need to define an optimizer that tracks all the learnable parameters inside `TwoLayerFC`.\n",
    "\n",
    "You don't need to tune any hyperparameters, but you should see model accuracies above 40% after training for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.2181\n",
      "Checking accuracy on validation set\n",
      "Got 154 / 1000 correct (15.40)\n",
      "\n",
      "Iteration 100, loss = 2.0808\n",
      "Checking accuracy on validation set\n",
      "Got 331 / 1000 correct (33.10)\n",
      "\n",
      "Iteration 200, loss = 2.2151\n",
      "Checking accuracy on validation set\n",
      "Got 380 / 1000 correct (38.00)\n",
      "\n",
      "Iteration 300, loss = 1.7748\n",
      "Checking accuracy on validation set\n",
      "Got 387 / 1000 correct (38.70)\n",
      "\n",
      "Iteration 400, loss = 1.8398\n",
      "Checking accuracy on validation set\n",
      "Got 378 / 1000 correct (37.80)\n",
      "\n",
      "Iteration 500, loss = 1.6134\n",
      "Checking accuracy on validation set\n",
      "Got 422 / 1000 correct (42.20)\n",
      "\n",
      "Iteration 600, loss = 1.8996\n",
      "Checking accuracy on validation set\n",
      "Got 439 / 1000 correct (43.90)\n",
      "\n",
      "Iteration 700, loss = 2.0856\n",
      "Checking accuracy on validation set\n",
      "Got 453 / 1000 correct (45.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module API: Train a Three-Layer ConvNet\n",
    "You should now use the Module API to train a three-layer ConvNet on CIFAR. This should look very similar to training the two-layer network! You don't need to tune any hyperparameters, but you should achieve above above 45% after training for one epoch.\n",
    "\n",
    "You should train the model using stochastic gradient descent without momentum.\n",
    "\n",
    "- 이제 Module API를 사용하여 CIFAR에서 3계층 ConvNet을 교육해야 합니다. 이것은 2계층 신경망을 훈련시키는 것과 매우 유사하게 보일 것입니다! 하이퍼파라미터를 조정할 필요는 없지만 한 에포크 동안 훈련한 후 45% 이상을 달성해야 합니다.\n",
    "\n",
    "- 모멘텀 없이 확률적 경사하강법을 사용하여 모델을 훈련해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "test": "module_accuracy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3099\n",
      "Checking accuracy on validation set\n",
      "Got 105 / 1000 correct (10.50)\n",
      "\n",
      "Iteration 100, loss = 2.2219\n",
      "Checking accuracy on validation set\n",
      "Got 225 / 1000 correct (22.50)\n",
      "\n",
      "Iteration 200, loss = 1.7611\n",
      "Checking accuracy on validation set\n",
      "Got 374 / 1000 correct (37.40)\n",
      "\n",
      "Iteration 300, loss = 1.4770\n",
      "Checking accuracy on validation set\n",
      "Got 412 / 1000 correct (41.20)\n",
      "\n",
      "Iteration 400, loss = 1.5065\n",
      "Checking accuracy on validation set\n",
      "Got 406 / 1000 correct (40.60)\n",
      "\n",
      "Iteration 500, loss = 1.7400\n",
      "Checking accuracy on validation set\n",
      "Got 423 / 1000 correct (42.30)\n",
      "\n",
      "Iteration 600, loss = 1.6391\n",
      "Checking accuracy on validation set\n",
      "Got 435 / 1000 correct (43.50)\n",
      "\n",
      "Iteration 700, loss = 1.3247\n",
      "Checking accuracy on validation set\n",
      "Got 475 / 1000 correct (47.50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "################################################################################\n",
    "# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model = ThreeLayerConvNet(in_channel=3, channel_1=channel_1, channel_2=channel_2, num_classes=10)\n",
    "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())\n",
    "\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. PyTorch Sequential API\n",
    "\n",
    "Part III introduced the PyTorch Module API, which allows you to define arbitrary learnable layers and their connectivity. \n",
    "\n",
    "For simple models like a stack of feed forward layers, you still need to go through 3 steps: subclass `nn.Module`, assign layers to class attributes in `__init__`, and call each layer one by one in `forward()`. Is there a more convenient way? \n",
    "\n",
    "Fortunately, PyTorch provides a container Module called `nn.Sequential`, which merges the above steps into one. It is not as flexible as `nn.Module`, because you cannot specify more complex topology than a feed-forward stack, but it's good enough for many use cases.\n",
    "\n",
    "해석\n",
    "- 3부에서는 임의의 학습 가능한 계층과 연결을 정의할 수 있는 PyTorch 모듈 API를 소개했습니다.\n",
    "\n",
    "- 피드 포워드 레이어 스택과 같은 간단한 모델의 경우에도 3단계를 거쳐야 합니다. `nn.Module` 하위 클래스, `__init__`에서 클래스 속성에 레이어 할당, `forward()`에서 각 레이어를 하나씩 호출 . 더 편리한 방법이 있습니까?\n",
    "\n",
    "- 다행스럽게도 PyTorch는 위의 단계를 하나로 병합하는 `nn.Sequential`이라는 컨테이너 모듈을 제공합니다. 피드포워드 스택보다 더 복잡한 토폴로지를 지정할 수 없기 때문에 `nn.Module`만큼 유연하지는 않지만 많은 사용 사례에 충분합니다.\n",
    "\n",
    "### Sequential API: Two-Layer Network\n",
    "Let's see how to rewrite our two-layer fully connected network example with `nn.Sequential`, and train it using the training loop defined above.\n",
    "\n",
    "Again, you don't need to tune any hyperparameters here, but you shoud achieve above 40% accuracy after one epoch of training.\n",
    "\n",
    "해석\n",
    "- `nn.Sequential`로 완전히 연결된 2계층 네트워크 예제를 다시 작성하고 위에 정의된 훈련 루프를 사용하여 훈련시키는 방법을 살펴보겠습니다.\n",
    "\n",
    "- 다시 말하지만 여기서는 하이퍼파라미터를 조정할 필요가 없지만 한 에폭의 훈련 후에 40% 이상의 정확도를 달성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3853\n",
      "Checking accuracy on validation set\n",
      "Got 175 / 1000 correct (17.50)\n",
      "\n",
      "Iteration 100, loss = 1.6267\n",
      "Checking accuracy on validation set\n",
      "Got 401 / 1000 correct (40.10)\n",
      "\n",
      "Iteration 200, loss = 1.7888\n",
      "Checking accuracy on validation set\n",
      "Got 424 / 1000 correct (42.40)\n",
      "\n",
      "Iteration 300, loss = 1.8822\n",
      "Checking accuracy on validation set\n",
      "Got 423 / 1000 correct (42.30)\n",
      "\n",
      "Iteration 400, loss = 1.9303\n",
      "Checking accuracy on validation set\n",
      "Got 460 / 1000 correct (46.00)\n",
      "\n",
      "Iteration 500, loss = 1.4937\n",
      "Checking accuracy on validation set\n",
      "Got 423 / 1000 correct (42.30)\n",
      "\n",
      "Iteration 600, loss = 1.8480\n",
      "Checking accuracy on validation set\n",
      "Got 432 / 1000 correct (43.20)\n",
      "\n",
      "Iteration 700, loss = 1.9202\n",
      "Checking accuracy on validation set\n",
      "Got 420 / 1000 correct (42.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to wrap `flatten` function in a module in order to stack it\n",
    "# in nn.Sequential\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 10),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                     momentum=0.9, nesterov=True)\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API: Three-Layer ConvNet\n",
    "Here you should use `nn.Sequential` to define and train a three-layer ConvNet with the same architecture we used in Part III:\n",
    "\n",
    "1. Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2\n",
    "2. ReLU\n",
    "3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n",
    "4. ReLU\n",
    "5. Fully-connected layer (with bias) to compute scores for 10 classes\n",
    "\n",
    "You can use the default PyTorch weight initialization.\n",
    "\n",
    "You should optimize your model using stochastic gradient descent with Nesterov momentum 0.9.\n",
    "\n",
    "Again, you don't need to tune any hyperparameters but you should see accuracy above 55% after one epoch of training.\n",
    "\n",
    "\n",
    "해석\n",
    "- 여기서 `nn.Sequential`을 사용하여 3부에서 사용한 것과 동일한 아키텍처로 3계층 ConvNet을 정의하고 훈련해야 합니다.\n",
    "\n",
    "- 1. 제로 패딩이 2인 32개의 5x5 필터가 있는 컨벌루션 레이어(바이어스 포함)\n",
    "- 2. 렐루\n",
    "- 3. 제로 패딩이 1인 16개의 3x3 필터가 있는 컨벌루션 레이어(바이어스 포함)\n",
    "- 4. 렐루\n",
    "- 5. 10개의 클래스에 대한 점수를 계산하기 위한 완전 연결 레이어(바이어스 있음)\n",
    "\n",
    "- 기본 PyTorch 가중치 초기화를 사용할 수 있습니다.\n",
    "\n",
    "- Nesterov 모멘텀 0.9로 확률적 경사하강법을 사용하여 모델을 최적화해야 합니다.\n",
    "\n",
    "- 다시 말하지만 하이퍼파라미터를 조정할 필요는 없지만 한 에폭의 훈련 후에 정확도가 55% 이상이어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "test": "sequential_accuracy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3079\n",
      "Checking accuracy on validation set\n",
      "Got 156 / 1000 correct (15.60)\n",
      "\n",
      "Iteration 100, loss = 1.6986\n",
      "Checking accuracy on validation set\n",
      "Got 405 / 1000 correct (40.50)\n",
      "\n",
      "Iteration 200, loss = 1.6193\n",
      "Checking accuracy on validation set\n",
      "Got 482 / 1000 correct (48.20)\n",
      "\n",
      "Iteration 300, loss = 1.0952\n",
      "Checking accuracy on validation set\n",
      "Got 526 / 1000 correct (52.60)\n",
      "\n",
      "Iteration 400, loss = 1.3969\n",
      "Checking accuracy on validation set\n",
      "Got 529 / 1000 correct (52.90)\n",
      "\n",
      "Iteration 500, loss = 1.2530\n",
      "Checking accuracy on validation set\n",
      "Got 550 / 1000 correct (55.00)\n",
      "\n",
      "Iteration 600, loss = 1.2929\n",
      "Checking accuracy on validation set\n",
      "Got 554 / 1000 correct (55.40)\n",
      "\n",
      "Iteration 700, loss = 1.1754\n",
      "Checking accuracy on validation set\n",
      "Got 602 / 1000 correct (60.20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "learning_rate = 1e-2\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "################################################################################\n",
    "# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n",
    "# Sequential API.                                                              #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=channel_1, kernel_size=(5,5), padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=channel_2, kernel_size=(3,3), padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(16384,10)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(lr=learning_rate, momentum=0.9, nesterov=True,\n",
    "                       params=model.parameters())\n",
    "\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "train_part34(model, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 open-ended challenge\n",
    "\n",
    "In this section, you can experiment with whatever ConvNet architecture you'd like on CIFAR-10. \n",
    "\n",
    "Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves **at least 70%** accuracy on the CIFAR-10 **validation** set within 10 epochs. You can use the check_accuracy and train functions from above. You can use either `nn.Module` or `nn.Sequential` API. \n",
    "\n",
    "Describe what you did at the end of this notebook.\n",
    "\n",
    "Here are the official API documentation for each component. One note: what we call in the class \"spatial batch norm\" is called \"BatchNorm2D\" in PyTorch.\n",
    "\n",
    "* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n",
    "* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "해석\n",
    "- 이 섹션에서는 CIFAR-10에서 원하는 모든 ConvNet 아키텍처를 실험할 수 있습니다.\n",
    "\n",
    "- 이제 아키텍처, 하이퍼파라미터, 손실 함수 및 옵티마이저를 실험하여 10 에포크 내에서 설정된 CIFAR-10 **검증**에서 **최소 70%** 정확도를 달성하는 모델을 교육하는 것이 귀하의 임무입니다. 위의 check_accuracy 및 train 함수를 사용할 수 있습니다. `nn.Module` 또는 `nn.Sequential` API를 사용할 수 있습니다.\n",
    "\n",
    "- 이 공책의 끝에서 무엇을 했는지 설명하십시오.\n",
    "\n",
    "- 다음은 각 구성 요소에 대한 공식 API 설명서입니다. 한 가지 참고: \"공간 배치 표준\" 클래스에서 호출하는 것은 PyTorch에서 \"BatchNorm2D\"라고 합니다.\n",
    "\n",
    "* torch.nn 패키지의 레이어: http://pytorch.org/docs/stable/nn.html\n",
    "* 활성화: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
    "* 손실 함수: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "* 옵티마이저: http://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "\n",
    "### Things you might try:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "\n",
    "해석\n",
    "- **필터 크기**: 위에서는 5x5를 사용했습니다. 더 작은 필터가 더 효율적일까요? 작으면 작을 수록 파라미터갯수를 줄일 수 있고, 3*3개 conv를 3개 배치하면 7 * 7 같은 효과가 발생한다.\n",
    "- 답변 : 작으면 작을 수록 파라미터갯수를 줄일 수 있고, 3*3개 conv를 3개 배치하면 7 * 7 같은 효과가 발생한다.\n",
    "\n",
    "- **필터 수**: 위에서 32개의 필터를 사용했습니다. 더 많이 또는 적게 더 잘합니까?\n",
    "- 답변 : 필터의 수가 많으면 파라미터 수가 증가하여 과접합이 발생할 수 있다.\n",
    "\n",
    "- **풀링 대 스트라이드 컨볼루션**: 최대 풀링을 사용합니까, 아니면 스트라이드 컨볼루션만 사용합니까?\n",
    "- 답변 : stride를 사용하면 더욱 섬세하게 작동할 수 있다. 하지만 많은 파라미터가 생기기 때문에 pooling 사용하여 스케일을 줄여 conv에서는 가급적 유지하고, pooling에서는 스케일을 낮추는 것을 추천한다.\n",
    "\n",
    "- **배치 정규화**: 컨볼루션 레이어 뒤에 공간 배치 정규화를 추가하고 아핀 레이어 뒤에 바닐라 배치 정규화를 추가해 보세요. 네트워크가 더 빠르게 훈련됩니까?\n",
    "- 답변 : 뇌 관찰에서 억제 체계를 구현하려는 의도가 있어지만, 실제로는 억제 체계가 미미한것으로 나타난다.\n",
    "\n",
    "\n",
    "- **네트워크 아키텍처**: 위의 네트워크에는 훈련 가능한 매개변수의 두 계층이 있습니다. 딥 네트워크로 더 잘할 수 있습니까? 시도해 볼 만한 좋은 아키텍처는 다음과 같습니다.\n",
    "     - [conv-relu-pool]xN -> [affine]xM -> [softmax 또는 SVM]\n",
    "     - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax 또는 SVM]\n",
    "     - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax 또는 SVM]\n",
    "\n",
    "- **전역 평균 풀링**: 평면화한 다음 여러 아핀 레이어를 갖는 대신 이미지가 작아질 때까지 컨볼루션을 수행한 다음(7x7 정도) 평균 풀링 작업을 수행하여 1x1 이미지 사진(1, 1, Filter#), 그런 다음 (Filter#) 벡터로 모양이 변경됩니다. 이는 [Google의 Inception Network](https://arxiv.org/abs/1512.00567)에서 사용됩니다(아키텍처는 표 1 참조).\n",
    "- **정규화**: l2 가중치 정규화를 추가하거나 드롭아웃을 사용할 수 있습니다.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these, but don't miss the fun if you have time!\n",
    "\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "### Have fun and happy training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=output_channel,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3,3), padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.classes = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Dropout(0.2, inplace=True),\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        conv = self.conv(x)\n",
    "        a = self.classes(conv)\n",
    "        return a\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "test": "open_ended_accuracy",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3028\n",
      "Checking accuracy on validation set\n",
      "Got 106 / 1000 correct (10.60)\n",
      "\n",
      "Iteration 100, loss = 2.1230\n",
      "Checking accuracy on validation set\n",
      "Got 238 / 1000 correct (23.80)\n",
      "\n",
      "Iteration 200, loss = 1.8737\n",
      "Checking accuracy on validation set\n",
      "Got 321 / 1000 correct (32.10)\n",
      "\n",
      "Iteration 300, loss = 1.6426\n",
      "Checking accuracy on validation set\n",
      "Got 422 / 1000 correct (42.20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #         \n",
    "# Experiment with any architectures, optimizers, and hyperparameters.          #\n",
    "# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n",
    "#                                                                              #\n",
    "# Note that you can use the check_accuracy function to evaluate on either      #\n",
    "# the test set or the validation set, by passing either loader_test or         #\n",
    "# loader_val as the second argument to check_accuracy. You should not touch    #\n",
    "# the test set until you have finished your architecture and  hyperparameter   #\n",
    "# tuning, and only run the test set once at the end to report a final value.   #\n",
    "################################################################################\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model = MyModel(input_channel=3, output_channel=64, num_classes=10)\n",
    "optimizer = optim.SGD(lr=learning_rate, momentum=0.9, nesterov=True,\n",
    "                       params=model.parameters())\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# You should get at least 70% accuracy.\n",
    "# You may modify the number of epochs to any number below 15.\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Answer:**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model). Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
